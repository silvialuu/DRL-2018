# DRL-2018
------------
This repository features work from 2018 summer research project on deep reinforcement learning (advised by Prof. Keith Ross, funded by NYU Shanghai Dean's Undergraduate Research Fund). In this project, we experimented with combining Policy Gradient methods -- vanilla Policy Gradient (aka REINFORCE), Actor-Critic, and PPO --  with Evolution Strategies to devise a hybrid algorithm with improved sample efficiency. Performances of the proposed algorithms were evaluated on MuJoCo benchmarks.

References:
* REINFORCE: Ronald J Williams. Simple statistical gradient-following algorithms for connec- tionist reinforcement learning. Machine learning, 8(3-4):229–256, 1992.
* Actor-Critic: Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. Policy gradient methods for reinforcement learning with function approximation. In Advances in neural information processing systems, pages 1057–1063, 2000.
* PPO: John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.
* Evolution Strategy: Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864, 2017.
